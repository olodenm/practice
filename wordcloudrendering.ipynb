{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olodenm/practice/blob/main/wordcloudrendering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Скрипт для генирации \"Облака слов\" из выгрузки личной переписки с Telegram\n",
        "\n",
        "## Как использовать этот код\n",
        "\n",
        "1. **Получите свой JSON-файл**: Этот код предназначен для работы с JSON-файлами. Для этого вам нужно открыть Telegram desktop, зайти в переписку которую хотите выгрузить. Нажать на три точки в верхнем правом углу экрана, \"экспорт истории чата\" затем выбираем формат \"Машиночитаемый JSON\", путь можно указать любой удобный. выбрать диапазон дат, и нажать кнопку \"Экспортировать\"\n",
        "\n",
        "2. **Загрузите JSON-файл в ту же директорию, что и код**: После того, как у вас есть JSON-файл, вы должны загрузить его в ту же директорию, что и ваш код. Это позволит коду легко найти и загрузить ваш JSON-файл.\n",
        "\n",
        "3. **Убедитесь, что ваш JSON-файл имеет правильный формат**: Этот код ожидает, что ваш JSON-файл будет иметь определенный формат. В частности, он ожидает, что JSON-файл будет содержать ключ 'messages', который ссылается на список сообщений. Каждое сообщение должно быть словарем с ключом 'text', который ссылается на текст сообщения.\n",
        "\n",
        "4. **Запустите код**: Теперь вы готовы запустить код! Если вы все сделали правильно, код должен успешно загрузить ваш JSON-файл, обработать текст сообщений и создать облако слов.\n",
        "\n",
        "Если у вас возникнут вопросы или проблемы, не стесняйтесь обращаться!\n"
      ],
      "metadata": {
        "id": "Xd2nKAM9NLF5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1Y3yQi8cbTwY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZziS2J-3xeG"
      },
      "outputs": [],
      "source": [
        "# Загружаем данные из JSON-файла\n",
        "df = pd.read_json('result.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npgEgc5gYD0X"
      },
      "outputs": [],
      "source": [
        "# Вывести значения ключа 'text' из словарей в столбце 'messages'\n",
        "texts = df['messages'].apply(lambda x: x.get('text') if x else None)\n",
        "\n",
        "# Убрать строки, где ключ 'text' отсутствует\n",
        "texts = texts.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "natjG7ygYD3B"
      },
      "outputs": [],
      "source": [
        "# Преобразовать Series в DataFrame\n",
        "df = texts.to_frame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IoOQIp6YD5q"
      },
      "outputs": [],
      "source": [
        "# Приводим весь текст к нижнему регистру;\n",
        "df['messages'] = df['messages'].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yW4GvbwdYD8V"
      },
      "outputs": [],
      "source": [
        "# Удалить строки, в которых 'messages' пустой\n",
        "df = df[df['messages'].notna() & (df['messages'] != '')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqvDN0avYD--"
      },
      "outputs": [],
      "source": [
        "# уберем все служебные символы\n",
        "df['messages'] = [re.sub('[\\W_]+', ' ', text) for text in df['messages']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cZfeNHqYEBk"
      },
      "outputs": [],
      "source": [
        "# Удаляем стоп-слова;\n",
        "nltk.download('stopwords')\n",
        "stopwords_set = set(stopwords.words('russian'))\n",
        "df['messages'] = df['messages'].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords_set]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDOgKwbwYEEP"
      },
      "outputs": [],
      "source": [
        "# Произведем лемматизацию\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "df['messages'] = df['messages'].apply(lambda x: ' '.join([wordnet_lemmatizer.lemmatize(word) for word in x.split() if word not in stopwords_set]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdzAUyLfeU5S"
      },
      "outputs": [],
      "source": [
        "# Удалить строки, в которых 'messages' пустой\n",
        "df = df[df['messages'].notna() & (df['messages'] != '')]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Параметры функции WordCloud:\n",
        "* **width**: Ширина изображения облака слов в пикселях.\n",
        "* **height**: Высота изображения облака слов в пикселях.\n",
        "* **background_color**: Цвет фона изображения облака слов. (представляет собой шестнадцатеричный код цвета.)\n",
        "* **mode**: Режим цвета для изображения. \"RGBA\" означает красный, зеленый, синий и альфа (прозрачность).\n",
        "* **collocations**: Если это значение установлено в True, то все биграммы (два слова, которые часто встречаются вместе) будут включены в облако слов.\n",
        "* **max_words**: Максимальное количество слов, которые будут отображаться в облаке слов.\n",
        "* **stopwords**: Набор стоп-слов, которые будут исключены из облака слов.\n"
      ],
      "metadata": {
        "id": "rTjsCQeQLnNj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRff5JEy5PfX"
      },
      "outputs": [],
      "source": [
        "# Объединить все строки в одну, разделенную пробелами\n",
        "text = ' '.join(df['messages'].dropna())\n",
        "\n",
        "# Обновить список стоп-слов, включая \"ещё\"\n",
        "stopwords_set.update(['ещё', 'это'])\n",
        "\n",
        "# Создание облака слов\n",
        "wordcloud = WordCloud(width=1000, height=1000, background_color='#141613', mode='RGBA', collocations=True, max_words=100, stopwords=stopwords_set)\n",
        "wordcloud.generate(text)\n",
        "\n",
        "# Визуализация облака слов\n",
        "plt.figure(figsize=(20,10)) # Размер изображения\n",
        "plt.imshow(wordcloud, interpolation='bicubic')\n",
        "plt.axis(\"off\")\n",
        "plt.margins(x=0, y=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Z5odNnK0gf0I"
      },
      "outputs": [],
      "source": [
        "# Сохранение изображения\n",
        "wordcloud.to_file(\"worldcloud.png\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbcbX7yhJKpjuEqcRz+d4z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}